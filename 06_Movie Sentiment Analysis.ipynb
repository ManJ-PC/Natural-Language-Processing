{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Link : https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o98OWYUj0fGf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, RNN, LSTM, GRU, Bidirectional, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxqqOmOU0uUL",
    "outputId": "d33711f9-8f65-4343-c1bd-dbedbad10de8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqpqAIKP0vCU"
   },
   "outputs": [],
   "source": [
    "####Reading Data\n",
    "train_df = pd.read_csv('/content/drive/MyDrive/Datasets/Sentiment Analysis/train.tsv', sep = '\\t')\n",
    "test_df = pd.read_csv('/content/drive/MyDrive/Datasets/Sentiment Analysis/test.tsv', sep = '\\t')\n",
    "sample_df = pd.read_csv('/content/drive/MyDrive/Datasets/Sentiment Analysis/sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "-M-stTdT4gCP",
    "outputId": "f456f694-62ac-4cfc-9510-bc3987d8a25b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  ...  Sentiment\n",
       "0         1  ...          1\n",
       "1         2  ...          2\n",
       "2         3  ...          2\n",
       "3         4  ...          2\n",
       "4         5  ...          2\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgZPgy8F1emP",
    "outputId": "673e93cb-1748-4ed5-d272-802835b7771e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import contractions\n",
    "from bs4 import BeautifulSoup \n",
    "import tqdm\n",
    "import unicodedata\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    [s.extract() for s in soup(['iframe', 'script'])]\n",
    "    stripped_text = soup.get_text()\n",
    "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "    return stripped_text\n",
    "\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "def pre_process_corpus(docs):\n",
    "    norm_docs = []\n",
    "    for text in tqdm.tqdm(docs): \n",
    "        text = strip_html_tags(text)\n",
    "        text = re.sub(r'[^a-zA-Z\\s]','',text,re.I)\n",
    "        text = text.lower()\n",
    "        text = text.strip()\n",
    "        text = remove_accented_chars(text)\n",
    "        text = contractions.fix(text)\n",
    "        #tokens = nltk.word_tokenize(text)\n",
    "        #filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "        #text = \" \".join(filtered_tokens)\n",
    "        text = re.sub(\" +\", ' ',text)\n",
    "        text =text.strip()\n",
    "        norm_docs.append(text)\n",
    "    return norm_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dJ1PLtSV1sWd",
    "outputId": "c7a75dfa-fb10-4e0d-e896-12f8f81620e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156060/156060 [00:20<00:00, 7742.46it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = pre_process_corpus(train_df['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CoIwjkTD17Oc",
    "outputId": "9c433bdc-271a-4e80-bbe1-c07a5708a5da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66292/66292 [00:08<00:00, 7967.39it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = pre_process_corpus(test_df['Phrase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g5pJpkRc2Hby"
   },
   "outputs": [],
   "source": [
    "def metrics(y_true,y_pred):\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_true, y_pred))\n",
    "    print('\\n\\nAccuracy Score:\\n', accuracy_score(y_true, y_pred))\n",
    "    print('\\n\\nClassification Report: \\n', classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0bu-gvs2PwC"
   },
   "outputs": [],
   "source": [
    "#Tokenizing the text\n",
    "tokenzer = tf.keras.preprocessing.text.Tokenizer(oov_token = '<UNK>')\n",
    "tokenzer.fit_on_texts(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdCMIHfQ3cDf"
   },
   "outputs": [],
   "source": [
    "train_sequences = tokenzer.texts_to_sequences(train_data)\n",
    "test_sequences = tokenzer.texts_to_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9Xnl5Zs3rE4",
    "outputId": "3c2fcd37-c5c3-46bc-e18a-de8e41c55e5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size =16692\n",
      "Number of Documents=156060\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size ={}\".format(len(tokenzer.word_index)))\n",
    "print(\"Number of Documents={}\".format(tokenzer.document_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8YzU-Qe033Ch",
    "outputId": "2493def8-fd54-4aea-8420-43ca54952d74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_data).apply(lambda x : len(x.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HlE71iFJ3t6H"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 51\n",
    "\n",
    "\n",
    "#Padding the sentence to the maximum length.\n",
    "train_pad_sequences = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "test_pad_sequneces = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen = MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2P_PhOel55Hk",
    "outputId": "ebfead9e-bad2-4502-e6ab-ca799618149f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 51)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad_sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uicdSMM_6K9H"
   },
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuESsMbp6wx2"
   },
   "outputs": [],
   "source": [
    " y = train_df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VYyNr9ql60qH",
    "outputId": "5e730292-630e-4d48-f315-fd2ae953af71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16692"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-BPqGmJ6k1t"
   },
   "outputs": [],
   "source": [
    "def deep_model(net_layer):\n",
    "  SEED = 42\n",
    "  np.random.seed(SEED)\n",
    "  tf.random.set_seed(SEED)\n",
    "\n",
    "  EMBEDDING_DIM = 300 #Dimension for dense embedding for each token\n",
    "  VOCAB_SIZE = len(tokenzer.word_index)\n",
    "  model = Sequential()\n",
    "  model.add((Embedding(input_dim =VOCAB_SIZE+1,output_dim = EMBEDDING_DIM,input_length = MAX_SEQUENCE_LENGTH)))\n",
    "  model.add(Bidirectional(net_layer(128,return_sequences = True)))\n",
    "  model.add(Bidirectional(net_layer(256,activation = 'relu', return_sequences=False)))\n",
    "  model.add(Dense(5,activation = 'softmax'))\n",
    "\n",
    "  model.compile(loss = 'sparse_categorical_crossentropy',optimizer=\"adam\",metrics =['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rHa6KUA968mM",
    "outputId": "c97fab35-9130-4512-ae69-c3c90d4eb000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 51, 300)           5007900   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 5,228,193\n",
      "Trainable params: 5,228,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UuNFjK0R7As0",
    "outputId": "73bc7e1d-c27d-4727-f41d-e5fcdbd48445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4390/4390 [==============================] - 313s 71ms/step - loss: 1.0515 - accuracy: 0.5824 - val_loss: 1.0216 - val_accuracy: 0.5904\n",
      "Epoch 2/5\n",
      "4390/4390 [==============================] - 310s 71ms/step - loss: 0.7743 - accuracy: 0.6860 - val_loss: 1.0051 - val_accuracy: 0.6066\n",
      "Epoch 3/5\n",
      "4390/4390 [==============================] - 309s 70ms/step - loss: 0.6875 - accuracy: 0.7178 - val_loss: 1.0334 - val_accuracy: 0.6027\n",
      "Epoch 4/5\n",
      "4390/4390 [==============================] - 303s 69ms/step - loss: 0.6296 - accuracy: 0.7404 - val_loss: 1.0449 - val_accuracy: 0.5923\n",
      "Epoch 5/5\n",
      "4390/4390 [==============================] - 301s 69ms/step - loss: 0.5815 - accuracy: 0.7566 - val_loss: 1.0831 - val_accuracy: 0.5945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f132cf90a10>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad_sequences, y, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FkF6g-L9Efda"
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict_classes(test_pad_sequneces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlM-BuzSGha9"
   },
   "outputs": [],
   "source": [
    "sample_df['Sentiment'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P46AXFoKGrFZ"
   },
   "outputs": [],
   "source": [
    "sample_df.to_csv('Predictions.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "T0IDxBBA7U1F",
    "outputId": "54f825dd-ce36-4719-8c1c-8208b6289ce2"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_5d064f73-514d-42d2-a19a-824f2f02835a\", \"Predictions.csv\", 596647)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download('Predictions.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkpLSjo-U6cZ"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "EMBEDDING_DIM = 300 #Dimension for dense embedding for each token\n",
    "VOCAB_SIZE = len(tokenzer.word_index)\n",
    "model = Sequential()\n",
    "model.add((Embedding(input_dim =VOCAB_SIZE+1,output_dim = EMBEDDING_DIM,input_length = MAX_SEQUENCE_LENGTH)))\n",
    "model.add((GRU(128,return_sequences = False)))\n",
    "model.add((Dense(256,activation = 'relu',)))\n",
    "model.add(Dense(5,activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',optimizer=\"adam\",metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8dHdjRh7Uxis",
    "outputId": "f4efd3ca-d63f-45c9-9370-607cf7202393"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 51, 300)           5007900   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               165120    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 5,207,329\n",
      "Trainable params: 5,207,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "meTaGtaEUb8h",
    "outputId": "8bcbb799-1f92-4f5f-fd07-f12c54ac3267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4390/4390 [==============================] - 313s 69ms/step - loss: 0.9853 - accuracy: 0.6063 - val_loss: 0.9818 - val_accuracy: 0.6073\n",
      "Epoch 2/5\n",
      "4390/4390 [==============================] - 298s 68ms/step - loss: 0.7365 - accuracy: 0.6983 - val_loss: 0.9778 - val_accuracy: 0.6109\n",
      "Epoch 3/5\n",
      "4390/4390 [==============================] - 297s 68ms/step - loss: 0.6553 - accuracy: 0.7284 - val_loss: 1.0081 - val_accuracy: 0.5965\n",
      "Epoch 4/5\n",
      "4390/4390 [==============================] - 293s 67ms/step - loss: 0.5987 - accuracy: 0.7481 - val_loss: 1.0451 - val_accuracy: 0.5996\n",
      "Epoch 5/5\n",
      "4390/4390 [==============================] - 297s 68ms/step - loss: 0.5481 - accuracy: 0.7667 - val_loss: 1.0733 - val_accuracy: 0.5942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1321342090>"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad_sequences, y, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "NFqUYGuiUsHN",
    "outputId": "51fa9956-2fa0-4183-8d14-4a700831ec4f"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_00bd95bf-51d4-4e73-8e13-d9f6abc76ed1\", \"Predictions1.csv\", 596647)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_pred = model.predict_classes(test_pad_sequneces)\n",
    "sample_df['Sentiment'] = test_pred\n",
    "sample_df.to_csv('Predictions1.csv', index = None)\n",
    "from google.colab import files\n",
    "files.download('Predictions1.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRYOWEaxbbng"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "EMBEDDING_DIM = 300 #Dimension for dense embedding for each token\n",
    "VOCAB_SIZE = len(tokenzer.word_index)\n",
    "model = Sequential()\n",
    "model.add((Embedding(input_dim =VOCAB_SIZE+1,output_dim = EMBEDDING_DIM,input_length = MAX_SEQUENCE_LENGTH)))\n",
    "model.add(Bidirectional(GRU(128,return_sequences = False)))\n",
    "model.add((Dense(256,activation = 'relu',)))\n",
    "model.add(Dense(5,activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',optimizer=\"adam\",metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B_dte1FDcPYQ",
    "outputId": "f48777e6-9615-42e2-f2bd-e4edba95a699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 51, 300)           5007900   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 256)               330240    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 5,405,217\n",
      "Trainable params: 5,405,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sI-FjMUBcMTB",
    "outputId": "381a5760-5149-46b7-b9b6-f8c5fd1c3d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4390/4390 [==============================] - 360s 82ms/step - loss: 0.8822 - accuracy: 0.6408 - val_loss: 0.9687 - val_accuracy: 0.6094\n",
      "Epoch 2/2\n",
      "4390/4390 [==============================] - 361s 82ms/step - loss: 0.7076 - accuracy: 0.7061 - val_loss: 0.9818 - val_accuracy: 0.6087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1322ba3610>"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_pad_sequences, y, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "tCgvD0tccRJj",
    "outputId": "47024c6b-1cf8-45ea-e7b3-0b754dc5aa89"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_03d89930-7358-4fda-93a2-13f9fc8d7d8c\", \"Predictions2.csv\", 596647)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_pred = model.predict_classes(test_pad_sequneces)\n",
    "sample_df['Sentiment'] = test_pred\n",
    "sample_df.to_csv('Predictions2.csv', index = None)\n",
    "from google.colab import files\n",
    "files.download('Predictions2.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-kCprb8YfMUq",
    "outputId": "962990e3-5136-4ca7-9d9d-dcf73dfb55a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.fasttext.FastText at 0x7f131b550510>"
      ]
     },
     "execution_count": 143,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "tokenized_corpus = [nltk.word_tokenize(doc) for doc in train_data]\n",
    "\n",
    "\n",
    "# Set values for various parameters\n",
    "feature_size = 49    # Word vector dimensionality  \n",
    "window_context = 20  # Context window size                                                                                    \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "sample = 1e-3        # Downsample setting for frequent words\n",
    "sg = 1               # skip-gram model\n",
    "\n",
    "ft_model = FastText(tokenized_corpus, size=feature_size, \n",
    "                     window=window_context, min_count = min_word_count,\n",
    "                      sample=sample)\n",
    "ft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etPQHoCEgeuG"
   },
   "outputs": [],
   "source": [
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "7Oo_zP61hJrk",
    "outputId": "33960fb1-914a-42e9-a925-94d97d3d7132"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.441281</td>\n",
       "      <td>0.507160</td>\n",
       "      <td>0.770722</td>\n",
       "      <td>0.963138</td>\n",
       "      <td>-0.685655</td>\n",
       "      <td>0.536615</td>\n",
       "      <td>-0.616827</td>\n",
       "      <td>-1.348408</td>\n",
       "      <td>-0.762274</td>\n",
       "      <td>-1.615198</td>\n",
       "      <td>0.014602</td>\n",
       "      <td>0.081998</td>\n",
       "      <td>-0.091562</td>\n",
       "      <td>0.356291</td>\n",
       "      <td>0.123390</td>\n",
       "      <td>-0.110576</td>\n",
       "      <td>-0.063605</td>\n",
       "      <td>1.041040</td>\n",
       "      <td>0.611392</td>\n",
       "      <td>-0.686466</td>\n",
       "      <td>1.179276</td>\n",
       "      <td>-0.152338</td>\n",
       "      <td>0.238797</td>\n",
       "      <td>-0.731713</td>\n",
       "      <td>-1.017957</td>\n",
       "      <td>0.016979</td>\n",
       "      <td>-0.051265</td>\n",
       "      <td>0.116101</td>\n",
       "      <td>-0.264996</td>\n",
       "      <td>0.012833</td>\n",
       "      <td>-1.429424</td>\n",
       "      <td>1.251031</td>\n",
       "      <td>-0.107272</td>\n",
       "      <td>0.775669</td>\n",
       "      <td>0.222352</td>\n",
       "      <td>-0.233242</td>\n",
       "      <td>-1.387988</td>\n",
       "      <td>0.991425</td>\n",
       "      <td>-0.177540</td>\n",
       "      <td>1.042039</td>\n",
       "      <td>0.685612</td>\n",
       "      <td>0.359440</td>\n",
       "      <td>-0.834138</td>\n",
       "      <td>0.344184</td>\n",
       "      <td>0.400826</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>-0.232304</td>\n",
       "      <td>-0.166370</td>\n",
       "      <td>-0.883356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.168005</td>\n",
       "      <td>0.801699</td>\n",
       "      <td>0.939617</td>\n",
       "      <td>0.809995</td>\n",
       "      <td>-0.776177</td>\n",
       "      <td>0.614697</td>\n",
       "      <td>-0.655630</td>\n",
       "      <td>-1.702683</td>\n",
       "      <td>-0.813289</td>\n",
       "      <td>-1.584852</td>\n",
       "      <td>0.201309</td>\n",
       "      <td>0.520248</td>\n",
       "      <td>-0.362777</td>\n",
       "      <td>0.524063</td>\n",
       "      <td>-0.192547</td>\n",
       "      <td>0.304437</td>\n",
       "      <td>-0.290311</td>\n",
       "      <td>1.401913</td>\n",
       "      <td>0.635816</td>\n",
       "      <td>-0.841760</td>\n",
       "      <td>1.360745</td>\n",
       "      <td>-0.234164</td>\n",
       "      <td>0.342971</td>\n",
       "      <td>-1.065689</td>\n",
       "      <td>-1.372238</td>\n",
       "      <td>-0.050935</td>\n",
       "      <td>0.356988</td>\n",
       "      <td>-0.212063</td>\n",
       "      <td>-0.353867</td>\n",
       "      <td>0.328919</td>\n",
       "      <td>-2.032985</td>\n",
       "      <td>1.435735</td>\n",
       "      <td>-0.343450</td>\n",
       "      <td>0.234330</td>\n",
       "      <td>-0.197409</td>\n",
       "      <td>-0.088049</td>\n",
       "      <td>-1.322677</td>\n",
       "      <td>1.230937</td>\n",
       "      <td>-0.785732</td>\n",
       "      <td>1.143249</td>\n",
       "      <td>0.915367</td>\n",
       "      <td>-0.002461</td>\n",
       "      <td>-0.887440</td>\n",
       "      <td>0.332560</td>\n",
       "      <td>-0.138139</td>\n",
       "      <td>0.092353</td>\n",
       "      <td>-0.327582</td>\n",
       "      <td>0.154532</td>\n",
       "      <td>-1.386927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.082305</td>\n",
       "      <td>-1.190333</td>\n",
       "      <td>1.734503</td>\n",
       "      <td>0.663169</td>\n",
       "      <td>-2.296338</td>\n",
       "      <td>-1.948801</td>\n",
       "      <td>-1.246404</td>\n",
       "      <td>-2.080420</td>\n",
       "      <td>-0.272343</td>\n",
       "      <td>-4.219652</td>\n",
       "      <td>0.457873</td>\n",
       "      <td>0.341550</td>\n",
       "      <td>-1.632678</td>\n",
       "      <td>-1.808780</td>\n",
       "      <td>-4.219624</td>\n",
       "      <td>1.107930</td>\n",
       "      <td>-2.445264</td>\n",
       "      <td>2.444481</td>\n",
       "      <td>1.580593</td>\n",
       "      <td>-1.196576</td>\n",
       "      <td>0.178263</td>\n",
       "      <td>0.582394</td>\n",
       "      <td>-1.228230</td>\n",
       "      <td>-1.858072</td>\n",
       "      <td>-2.075518</td>\n",
       "      <td>0.149812</td>\n",
       "      <td>1.171370</td>\n",
       "      <td>-0.388425</td>\n",
       "      <td>2.112467</td>\n",
       "      <td>-2.141758</td>\n",
       "      <td>0.097670</td>\n",
       "      <td>0.673594</td>\n",
       "      <td>0.636769</td>\n",
       "      <td>-1.167665</td>\n",
       "      <td>-1.950518</td>\n",
       "      <td>0.608850</td>\n",
       "      <td>0.544809</td>\n",
       "      <td>-0.201297</td>\n",
       "      <td>0.027539</td>\n",
       "      <td>3.750437</td>\n",
       "      <td>0.539078</td>\n",
       "      <td>-0.917777</td>\n",
       "      <td>-0.550623</td>\n",
       "      <td>-0.415097</td>\n",
       "      <td>-2.100217</td>\n",
       "      <td>-3.467077</td>\n",
       "      <td>0.540397</td>\n",
       "      <td>1.917396</td>\n",
       "      <td>-0.900434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.697802</td>\n",
       "      <td>-4.951401</td>\n",
       "      <td>2.966700</td>\n",
       "      <td>1.320312</td>\n",
       "      <td>-3.661474</td>\n",
       "      <td>-4.547944</td>\n",
       "      <td>-1.725259</td>\n",
       "      <td>-3.498343</td>\n",
       "      <td>1.237312</td>\n",
       "      <td>-4.477345</td>\n",
       "      <td>-0.792848</td>\n",
       "      <td>-1.869729</td>\n",
       "      <td>-0.596482</td>\n",
       "      <td>-3.945305</td>\n",
       "      <td>-9.632492</td>\n",
       "      <td>1.499200</td>\n",
       "      <td>-2.689227</td>\n",
       "      <td>2.345210</td>\n",
       "      <td>4.558747</td>\n",
       "      <td>-3.663603</td>\n",
       "      <td>1.086571</td>\n",
       "      <td>0.667651</td>\n",
       "      <td>-2.246895</td>\n",
       "      <td>-4.176065</td>\n",
       "      <td>-5.119275</td>\n",
       "      <td>1.032008</td>\n",
       "      <td>1.634493</td>\n",
       "      <td>-1.357201</td>\n",
       "      <td>3.614936</td>\n",
       "      <td>-4.288655</td>\n",
       "      <td>-1.689688</td>\n",
       "      <td>1.469756</td>\n",
       "      <td>1.896605</td>\n",
       "      <td>-4.248006</td>\n",
       "      <td>-2.581291</td>\n",
       "      <td>0.954061</td>\n",
       "      <td>0.388410</td>\n",
       "      <td>-0.904007</td>\n",
       "      <td>0.603925</td>\n",
       "      <td>6.281253</td>\n",
       "      <td>1.905752</td>\n",
       "      <td>-2.221319</td>\n",
       "      <td>2.029108</td>\n",
       "      <td>0.194640</td>\n",
       "      <td>-3.796067</td>\n",
       "      <td>-7.287859</td>\n",
       "      <td>3.721044</td>\n",
       "      <td>4.659659</td>\n",
       "      <td>-0.350704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.466809</td>\n",
       "      <td>2.570734</td>\n",
       "      <td>0.502305</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>-0.931203</td>\n",
       "      <td>0.650341</td>\n",
       "      <td>-0.767550</td>\n",
       "      <td>-0.662498</td>\n",
       "      <td>-1.781999</td>\n",
       "      <td>-3.961959</td>\n",
       "      <td>1.708593</td>\n",
       "      <td>2.552829</td>\n",
       "      <td>-2.668874</td>\n",
       "      <td>0.327746</td>\n",
       "      <td>1.193245</td>\n",
       "      <td>0.716660</td>\n",
       "      <td>-2.201302</td>\n",
       "      <td>2.543753</td>\n",
       "      <td>-1.397560</td>\n",
       "      <td>1.270452</td>\n",
       "      <td>-0.730045</td>\n",
       "      <td>0.497138</td>\n",
       "      <td>-0.209565</td>\n",
       "      <td>0.459922</td>\n",
       "      <td>0.968239</td>\n",
       "      <td>-0.732384</td>\n",
       "      <td>0.708248</td>\n",
       "      <td>0.580352</td>\n",
       "      <td>0.609998</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>1.885028</td>\n",
       "      <td>-0.122569</td>\n",
       "      <td>-0.623067</td>\n",
       "      <td>1.912675</td>\n",
       "      <td>-1.319745</td>\n",
       "      <td>0.263640</td>\n",
       "      <td>0.701208</td>\n",
       "      <td>0.501412</td>\n",
       "      <td>-0.548847</td>\n",
       "      <td>1.219622</td>\n",
       "      <td>-0.827596</td>\n",
       "      <td>0.385765</td>\n",
       "      <td>-3.130353</td>\n",
       "      <td>-1.024835</td>\n",
       "      <td>-0.404367</td>\n",
       "      <td>0.353705</td>\n",
       "      <td>-2.640249</td>\n",
       "      <td>-0.824868</td>\n",
       "      <td>-1.450164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>0.027831</td>\n",
       "      <td>-1.680416</td>\n",
       "      <td>-2.146590</td>\n",
       "      <td>3.390694</td>\n",
       "      <td>1.806233</td>\n",
       "      <td>-2.130845</td>\n",
       "      <td>3.805274</td>\n",
       "      <td>2.580997</td>\n",
       "      <td>-1.530487</td>\n",
       "      <td>-0.283533</td>\n",
       "      <td>0.712005</td>\n",
       "      <td>2.565607</td>\n",
       "      <td>2.812668</td>\n",
       "      <td>0.628975</td>\n",
       "      <td>0.440713</td>\n",
       "      <td>1.684730</td>\n",
       "      <td>0.379636</td>\n",
       "      <td>2.427021</td>\n",
       "      <td>2.849965</td>\n",
       "      <td>0.787010</td>\n",
       "      <td>-1.665470</td>\n",
       "      <td>-0.533214</td>\n",
       "      <td>-1.079587</td>\n",
       "      <td>-0.720003</td>\n",
       "      <td>-2.521146</td>\n",
       "      <td>-2.634955</td>\n",
       "      <td>0.061864</td>\n",
       "      <td>-1.760678</td>\n",
       "      <td>-1.765385</td>\n",
       "      <td>-1.314409</td>\n",
       "      <td>-1.507142</td>\n",
       "      <td>-0.756398</td>\n",
       "      <td>4.907889</td>\n",
       "      <td>-0.045379</td>\n",
       "      <td>0.754899</td>\n",
       "      <td>0.547549</td>\n",
       "      <td>-0.996275</td>\n",
       "      <td>2.882706</td>\n",
       "      <td>-1.665515</td>\n",
       "      <td>1.355999</td>\n",
       "      <td>2.346693</td>\n",
       "      <td>-1.072332</td>\n",
       "      <td>-0.395129</td>\n",
       "      <td>-0.140759</td>\n",
       "      <td>1.261219</td>\n",
       "      <td>-0.702689</td>\n",
       "      <td>1.237364</td>\n",
       "      <td>0.790287</td>\n",
       "      <td>-0.449721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>-0.435845</td>\n",
       "      <td>-0.241661</td>\n",
       "      <td>-0.797927</td>\n",
       "      <td>0.178291</td>\n",
       "      <td>-0.842554</td>\n",
       "      <td>0.078556</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>-0.363099</td>\n",
       "      <td>0.598639</td>\n",
       "      <td>-0.745922</td>\n",
       "      <td>0.770274</td>\n",
       "      <td>-0.532758</td>\n",
       "      <td>-0.179107</td>\n",
       "      <td>0.463224</td>\n",
       "      <td>0.871964</td>\n",
       "      <td>0.509950</td>\n",
       "      <td>0.913565</td>\n",
       "      <td>0.530192</td>\n",
       "      <td>-0.365935</td>\n",
       "      <td>1.001296</td>\n",
       "      <td>-0.244665</td>\n",
       "      <td>0.656734</td>\n",
       "      <td>-0.325951</td>\n",
       "      <td>0.385162</td>\n",
       "      <td>0.265360</td>\n",
       "      <td>-0.563258</td>\n",
       "      <td>1.219538</td>\n",
       "      <td>0.361481</td>\n",
       "      <td>0.376103</td>\n",
       "      <td>-0.157878</td>\n",
       "      <td>0.430186</td>\n",
       "      <td>0.228215</td>\n",
       "      <td>-1.177875</td>\n",
       "      <td>-0.061690</td>\n",
       "      <td>0.238511</td>\n",
       "      <td>0.580967</td>\n",
       "      <td>0.063902</td>\n",
       "      <td>-0.360662</td>\n",
       "      <td>0.059176</td>\n",
       "      <td>0.456086</td>\n",
       "      <td>0.477954</td>\n",
       "      <td>0.725752</td>\n",
       "      <td>-1.703660</td>\n",
       "      <td>-0.449515</td>\n",
       "      <td>-0.125843</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>-0.580625</td>\n",
       "      <td>-0.434410</td>\n",
       "      <td>0.029593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>0.290090</td>\n",
       "      <td>0.574622</td>\n",
       "      <td>-0.635888</td>\n",
       "      <td>-0.070264</td>\n",
       "      <td>-0.120952</td>\n",
       "      <td>0.122232</td>\n",
       "      <td>0.281980</td>\n",
       "      <td>0.310143</td>\n",
       "      <td>0.041001</td>\n",
       "      <td>-1.235314</td>\n",
       "      <td>0.733661</td>\n",
       "      <td>-0.016907</td>\n",
       "      <td>-0.353532</td>\n",
       "      <td>-0.192541</td>\n",
       "      <td>0.134693</td>\n",
       "      <td>0.447150</td>\n",
       "      <td>0.113940</td>\n",
       "      <td>0.704034</td>\n",
       "      <td>-0.360579</td>\n",
       "      <td>0.760385</td>\n",
       "      <td>-0.113371</td>\n",
       "      <td>0.059668</td>\n",
       "      <td>0.309657</td>\n",
       "      <td>0.063757</td>\n",
       "      <td>0.364116</td>\n",
       "      <td>-0.619797</td>\n",
       "      <td>0.283909</td>\n",
       "      <td>0.220115</td>\n",
       "      <td>0.506501</td>\n",
       "      <td>-0.107658</td>\n",
       "      <td>0.457066</td>\n",
       "      <td>0.260952</td>\n",
       "      <td>-0.180274</td>\n",
       "      <td>-0.295403</td>\n",
       "      <td>0.041801</td>\n",
       "      <td>0.553924</td>\n",
       "      <td>0.299237</td>\n",
       "      <td>-0.215105</td>\n",
       "      <td>-0.139460</td>\n",
       "      <td>0.717036</td>\n",
       "      <td>0.263782</td>\n",
       "      <td>0.450336</td>\n",
       "      <td>-1.210397</td>\n",
       "      <td>-0.127887</td>\n",
       "      <td>-0.479050</td>\n",
       "      <td>0.174391</td>\n",
       "      <td>-0.290044</td>\n",
       "      <td>-0.210351</td>\n",
       "      <td>0.119261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>0.215236</td>\n",
       "      <td>0.158858</td>\n",
       "      <td>-0.307407</td>\n",
       "      <td>-0.075581</td>\n",
       "      <td>0.313772</td>\n",
       "      <td>0.154443</td>\n",
       "      <td>0.233481</td>\n",
       "      <td>-0.041772</td>\n",
       "      <td>0.193552</td>\n",
       "      <td>-0.274997</td>\n",
       "      <td>-0.256786</td>\n",
       "      <td>-0.323671</td>\n",
       "      <td>-0.180062</td>\n",
       "      <td>-0.273472</td>\n",
       "      <td>-0.369169</td>\n",
       "      <td>0.308810</td>\n",
       "      <td>0.160816</td>\n",
       "      <td>0.226641</td>\n",
       "      <td>-0.061084</td>\n",
       "      <td>0.128424</td>\n",
       "      <td>-0.152972</td>\n",
       "      <td>0.088968</td>\n",
       "      <td>0.006102</td>\n",
       "      <td>-0.045651</td>\n",
       "      <td>0.295193</td>\n",
       "      <td>-0.253129</td>\n",
       "      <td>0.350407</td>\n",
       "      <td>-0.121626</td>\n",
       "      <td>0.264272</td>\n",
       "      <td>0.370952</td>\n",
       "      <td>0.198649</td>\n",
       "      <td>-0.155868</td>\n",
       "      <td>0.006966</td>\n",
       "      <td>-0.442073</td>\n",
       "      <td>0.597549</td>\n",
       "      <td>0.203542</td>\n",
       "      <td>0.067887</td>\n",
       "      <td>0.328318</td>\n",
       "      <td>-0.223108</td>\n",
       "      <td>0.476613</td>\n",
       "      <td>0.210406</td>\n",
       "      <td>0.241724</td>\n",
       "      <td>-0.407119</td>\n",
       "      <td>0.322760</td>\n",
       "      <td>-0.408473</td>\n",
       "      <td>0.015553</td>\n",
       "      <td>-0.029263</td>\n",
       "      <td>-0.056161</td>\n",
       "      <td>-0.006874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>0.364944</td>\n",
       "      <td>0.990386</td>\n",
       "      <td>-0.964370</td>\n",
       "      <td>-0.064947</td>\n",
       "      <td>-0.555677</td>\n",
       "      <td>0.090022</td>\n",
       "      <td>0.330479</td>\n",
       "      <td>0.662059</td>\n",
       "      <td>-0.111551</td>\n",
       "      <td>-2.195630</td>\n",
       "      <td>1.724109</td>\n",
       "      <td>0.289856</td>\n",
       "      <td>-0.527003</td>\n",
       "      <td>-0.111609</td>\n",
       "      <td>0.638555</td>\n",
       "      <td>0.585489</td>\n",
       "      <td>0.067064</td>\n",
       "      <td>1.181427</td>\n",
       "      <td>-0.660075</td>\n",
       "      <td>1.392346</td>\n",
       "      <td>-0.073770</td>\n",
       "      <td>0.030368</td>\n",
       "      <td>0.613212</td>\n",
       "      <td>0.173164</td>\n",
       "      <td>0.433040</td>\n",
       "      <td>-0.986465</td>\n",
       "      <td>0.217412</td>\n",
       "      <td>0.561855</td>\n",
       "      <td>0.748730</td>\n",
       "      <td>-0.586267</td>\n",
       "      <td>0.715484</td>\n",
       "      <td>0.677771</td>\n",
       "      <td>-0.367514</td>\n",
       "      <td>-0.148732</td>\n",
       "      <td>-0.513947</td>\n",
       "      <td>0.904306</td>\n",
       "      <td>0.530587</td>\n",
       "      <td>-0.758528</td>\n",
       "      <td>-0.055813</td>\n",
       "      <td>0.957459</td>\n",
       "      <td>0.317158</td>\n",
       "      <td>0.658948</td>\n",
       "      <td>-2.013675</td>\n",
       "      <td>-0.578534</td>\n",
       "      <td>-0.549627</td>\n",
       "      <td>0.333229</td>\n",
       "      <td>-0.550826</td>\n",
       "      <td>-0.364542</td>\n",
       "      <td>0.245396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2   ...        46        47        48\n",
       "0      -0.441281  0.507160  0.770722  ... -0.232304 -0.166370 -0.883356\n",
       "1      -0.168005  0.801699  0.939617  ... -0.327582  0.154532 -1.386927\n",
       "2       1.082305 -1.190333  1.734503  ...  0.540397  1.917396 -0.900434\n",
       "3       1.697802 -4.951401  2.966700  ...  3.721044  4.659659 -0.350704\n",
       "4       0.466809  2.570734  0.502305  ... -2.640249 -0.824868 -1.450164\n",
       "...          ...       ...       ...  ...       ...       ...       ...\n",
       "156055  0.027831 -1.680416 -2.146590  ...  1.237364  0.790287 -0.449721\n",
       "156056 -0.435845 -0.241661 -0.797927  ... -0.580625 -0.434410  0.029593\n",
       "156057  0.290090  0.574622 -0.635888  ... -0.290044 -0.210351  0.119261\n",
       "156058  0.215236  0.158858 -0.307407  ... -0.029263 -0.056161 -0.006874\n",
       "156059  0.364944  0.990386 -0.964370  ... -0.550826 -0.364542  0.245396\n",
       "\n",
       "[156060 rows x 49 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get document level embeddings\n",
    "ft_doc_features = averaged_word_vectorizer(corpus=tokenized_corpus, model=ft_model,\n",
    "                                             num_features=feature_size)\n",
    "pd.DataFrame(ft_doc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VIrWYH3iSRu"
   },
   "outputs": [],
   "source": [
    "test_corpus = [nltk.word_tokenize(doc) for doc in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVxXQcLmiN0q"
   },
   "outputs": [],
   "source": [
    "test_corpus = [nltk.word_tokenize(doc) for doc in test_data]\n",
    "test_doc_features = averaged_word_vectorizer(corpus=test_corpus, model=ft_model,\n",
    "                                             num_features=feature_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJLMCDRZitPc",
    "outputId": "849cc794-97a9-4cbd-bf4b-ce19ccfda756"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66292, 49)"
      ]
     },
     "execution_count": 147,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCpd-WDJmNd6"
   },
   "outputs": [],
   "source": [
    "train_doc_features_re = ft_doc_features.reshape(ft_doc_features.shape[0],ft_doc_features.shape[1],1)\n",
    "#X_test_pad_re = X_test_pad.reshape(599,49,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "131YMoa8mtPz"
   },
   "outputs": [],
   "source": [
    "test_doc_features_re = test_doc_features.reshape(test_doc_features.shape[0],ft_doc_features.shape[1],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nq6dLky6hMNr"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "EMBEDDING_DIM = 300 #Dimension for dense embedding for each token\n",
    "VOCAB_SIZE = len(tokenzer.word_index)\n",
    "model = Sequential()\n",
    "#model.add((Embedding(input_dim =VOCAB_SIZE+1,output_dim = EMBEDDING_DIM,input_length = MAX_SEQUENCE_LENGTH)))\n",
    "model.add((GRU(128, return_sequences = True, input_shape=(49,1))))\n",
    "model.add(Bidirectional(GRU(128, return_sequences=False)))\n",
    "model.add((Dense(256,activation = 'relu',)))\n",
    "model.add(Dense(5,activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',optimizer=\"adam\",metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WnqmaUHtiIRD",
    "outputId": "1cb45e31-1204-4067-cab6-9af2fa43cb7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_32 (GRU)                 (None, 49, 128)           50304     \n",
      "_________________________________________________________________\n",
      "bidirectional_22 (Bidirectio (None, 256)               198144    \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 315,525\n",
      "Trainable params: 315,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xk2Gv4OHizJc",
    "outputId": "36077171-3e73-4ea7-9ca3-b0cc6d127be7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4390/4390 [==============================] - 82s 17ms/step - loss: 1.1947 - accuracy: 0.5196 - val_loss: 1.2048 - val_accuracy: 0.5004\n",
      "Epoch 2/5\n",
      "4390/4390 [==============================] - 75s 17ms/step - loss: 1.1540 - accuracy: 0.5303 - val_loss: 1.1920 - val_accuracy: 0.5074\n",
      "Epoch 3/5\n",
      "4390/4390 [==============================] - 75s 17ms/step - loss: 1.1393 - accuracy: 0.5340 - val_loss: 1.1813 - val_accuracy: 0.5118\n",
      "Epoch 4/5\n",
      "4390/4390 [==============================] - 75s 17ms/step - loss: 1.1268 - accuracy: 0.5403 - val_loss: 1.1793 - val_accuracy: 0.5120\n",
      "Epoch 5/5\n",
      "4390/4390 [==============================] - 75s 17ms/step - loss: 1.1151 - accuracy: 0.5436 - val_loss: 1.1730 - val_accuracy: 0.5117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f131895fcd0>"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_doc_features_re, y, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "B5TbM_uSkTLT",
    "outputId": "f7286238-225e-447e-88d6-da0257e408fa"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_4cb01946-f17c-46f0-adc2-c1820c89ce33\", \"Predictions_fast.csv\", 596647)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_pred = model.predict_classes(test_doc_features_re)\n",
    "sample_df['Sentiment'] = test_pred\n",
    "sample_df.to_csv('Predictions_fast.csv', index = None)\n",
    "from google.colab import files\n",
    "files.download('Predictions_fast.csv') "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Kaggle Sentiment Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
